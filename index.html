<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fréchet Wavelet Distance</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <!-- (A) LOAD THE MATHJAX LIBRARY -->
<!-- DOCS: https://docs.mathjax.org/en/latest/basic/mathematics.html -->
<!-- DEMO: https://github.com/mathjax/MathJax-demos-web -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css">
    <!-- Bootstrap Font Icon CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css">
    <link rel="stylesheet" href="style.css">
</head>
 
<body>

    <div class="container-sm">
        <div class="headerContainer">
            <h1>Fréchet Wavelet Distance</h1>
            <h3>A Domain-Agnostic Metric for Image Generation</h3>
        </div>
        <div class="authorList">
            <a href="https://lokiv.dev/" class="refs">Lokesh Veeramacheneni</a><sup>1</sup>&emsp;
            <a href="https://www.wolter.tech/" class="refs">Moritz Wolter</a><sup>1</sup>&emsp;
            <a href="https://hildekuehne.github.io/" class="refs">Hilde Kuehne</a><sup>1,2</sup>&emsp;
            <a href="https://pages.iai.uni-bonn.de/gall_juergen/" class="refs">Juergen Gall</a><sup>1</sup><br>
            <sup>1</sup>University of Bonn&emsp;<sup>2</sup>University of Tübingen, MIT-IBM Watson AI Lab
        </div>
        <div class="buttonOrder">
            <a class="btn btns" href="https://arxiv.org/pdf/2312.15289" role="button"><i class="bi bi-file-earmark-pdf-fill"></i> paper</a>
            &nbsp;
            <a class="btn btns" href="https://github.com/Uni-Bonn-Attention-Research/frechet_wavelet_distance" role="button"><i class="bi bi-github"></i> code</a>
            &nbsp;
            <a class="btn btns" href="#" role="button"><i class="bi bi-box"></i> pip</a>
        </div>
    </div>

    <div class="container-sm">
        <div class="introImage">
            <figure>
                <img src="images/appadam.png" alt=""Intro Image" style='height: 100%; width: 80%; object-fit: contain'/>
                <figcaption>
                    For every center image, InceptionV3 predictions are depicted on the left.
                    The MSE between second and last image is smaller than the MSE between first two images.
                    This is because of presence of Microphone.
                    On the right, we depict level-3 packet transform and observe that MSE is smaller for first two images compared to other images.
                </figcaption>
            </figure>
        </div>
    </div>

    <div class="container-sm">
        <div class="abstract">
            <h2 class="sechead">Abstract</h2><br>
            <div class="abstract_text">
                <p>
                    Modern metrics for generative learning like Fréchet Inception Distance (FID)
                    demonstrate impressive performance. However, they suffer from various shortcomings, like a bias towards specific generators and datasets.
                <!-- </p>
                <p> -->
                    To address this problem, we propose the Fréchet Wavelet Distance (FWD) as a domain-agnostic metric
                    based on Wavelet Packet Transform \(\mathcal{W}_p\). FWD provides a sight across a broad
                    spectrum of frequencies in images with a high resolution, along with preserving
                    both spatial and textural aspects. Specifically, we use \(\mathcal{W}_p\) to project generated and
                    dataset images to packet coefficient space. Further, we compute Fréchet distance
                    with the resultant coefficients to evaluate the quality of a generator.
                <!-- </p>
                <p> -->
                    This metric is general-purpose and dataset-domain agnostic, as it does not rely on any pretrained
                    network while being more interpretable because of frequency band transparency.
                    We conclude with an extensive evaluation of a wide variety of generators across various datasets that the proposed FWD is able to generalize and improve robustness
                    to domain shift and various corruptions compared to other metrics.
                </p>
            </div>
        </div>
    </div>

    <div class="container-sm">
        <div class="secmethod">
            <h2 class="sechead">Fréchet Wavelet Distance</h2>
            <div class="methodImage">
                <figure>
                    <img src="images/methodology_img_compressed-1.png" alt="FWD Image" style='height: 100%; width: 100%; object-fit: contain'/>
                    <figcaption>
                        Fréchet Wavelet Distance (FWD) computation flow-chart. \(\mathcal{W}_p\) denotes the wavelet-packet
                        transform. Not all packet coefficients are shown, dashed lines indicate omissions. We compute
                        individual Fréchet Distances for each frequency band.
                    </figcaption>
                </figure>
            </div>
            <div class="abstract_text">
                <p>
                    We propose the Fréchet Wavelet Distance (FWD) to tackle the dataset-domain bias which inturn leverages Wavelet Packet Transform \(\mathcal{W}_p\).
                    In a nutshel, \(\mathcal{W}_p\) constructs a  tree of images by recursively convolving with the predefined filters. Example of wavelet packet transform is depicted in the below figure.
                    More details about the \(\mathcal{W}_p\) is found in Section:3 of the paper.
                </p>
            </div>
            <div class="methodImage">
                <figure>
                    <img src="images/lecun.png" alt="Packet transforms image" style='height: 100%; width: 100%; object-fit: contain'/>
                    <figcaption>
                        Illustration of the wavelet packet transform \(\mathcal{W}_p\). For visualization purpose, we depict recursion upto level 3. All the experiments in the paper are conducted with level 4 transform with Haar wavelet.
                    </figcaption>
                </figure>
            </div>

            <div class="abstract_text">
                <p>
                    The metric is computed in three steps. First, we compute the individual packet mean for the set of images
                    $$\mu_p(I_N) = \frac{1}{N} \sum_{n=1}^{N} \mathcal{W}(I_n)_p$$
                    with \(I_n\) being the \(n^{th}\) image in the dataset and p represent the corresponding packet from P packets. Then we compute the covariance matrix
                    $$\Sigma_p(I_n) = \frac{1}{N-1}\sum_{n=1}^{N}(\mathcal{W}(I_n)_p - \mu_p(I_N))(\mathcal{W}(I_n)_p - \mu_p(I_N))^T$$
                    Finally we compute the mean Fréchet distance across all packets.
                    $$FWD = \frac{1}{P}\sum_{p=1}^P ||\mu_{r_p} - \mu_{g_p}||_2^2 + \text{Tr}[\Sigma_{r_p} + \Sigma_{g_p} - 2\sqrt{\Sigma_{r_p}\Sigma_{g_p}}]$$
                    By averaging the distances of all frequency bands, the FWD captures frequency information across the spectrum.
                </p>
            </div>
        </div>
    </div>

    <div class="container-sm">
        <div class="results">
            <h2 class="sechead">Results</h2>
            <!-- <div class="resultImage1">
                <figure>
                    <img src="images/imagenetbias_imgs.png" alt="inet_bias_imgs" style='height: 70%; width: 70%; object-fit: contain'/>
                    <figcaption>
                        Uncurated samples from (a) Proj. FastGAN, (b) DDGAN models on CelebA-HQ dataset.
                        (c) and (d) represent samples from both the models on DNDD-Dataset respectively. The FID ranking
                        fluctuates, whereas our metric (FWD) provides a consistent ranking irrespective of the dataset.
                    </figcaption>
                </figure>
            </div> -->
            <div class="resultImage2">
                <figure>
                    <img src="images/imagenetbias_table.png" alt="inet_bias_table" style='height: 100%; width: 100%; object-fit: contain'/>
                    <figcaption>
                        Comparison of biased and unbiased Frèchet distances. FID denotes the standard formulation
                        using an InceptionV3 trained on ImageNet. To eliminate the imagenet bias we re-trained InceptionV3.
                        The FID (CelebA) and FID (DNDD-Dataset) columns list the distances measured using the retrained
                        networks as a backbone. We find that re-training is possible only for large datasets where sufficient
                        data is available. FWD consistently provides a meaningful metric.
                    </figcaption>
                </figure>
            </div>
            <div class="abstract_text">

            </div>
        </div>
    </div>

    <div class="container-sm">
        <div class="install">
            <h2 class="sechead">Use FWD</h2>
            <div class="code_install">
                &emsp;pip install pytorchfwd <br>
                &emsp;python -m pytorchfwd &lt;path_to_original_images&gt; &lt;path_to_generated_images&gt;
            </div>
            <h4 class="sechead">Options</h4>
            <div class="code_install">
                python -m pytorchfwd --help <br>
                <br>usage: pytorchfwd.py [-h] [--batch-size BATCH_SIZE] [--num-processes NUM_PROCESSES] [--save-packets] [--wavelet WAVELET] [--max_level MAX_LEVEL] [--log_scale] [--deterministic] path path <br>
                <br>positional arguments:<br>
                path                  Path to the generated images or path to .npz statistics file.<br>
                <br>
                options:<br>
                -h, --help            show this help message and exit<br>
                --batch-size          Batch size for wavelet packet transform. (default: 128)<br>
                --num-processes       Number of multiprocess. (default: None)<br>
                --save-packets        Save the packets as npz file. (default: False)<br>
                --wavelet             Choice of wavelet. (default: sym5)<br>
                --max_level           wavelet decomposition level (default: 4)<br>
                --log_scale           Use log scaling for wavelets. (default: False)<br>
                --deterministic       Set PyTorch to deterministic mode, for perfect reproducability. (default: False)<br>
            </div>
        </div>
    </div>

    <div class="container-sm">
        <div class="citation">
            <h2 class="sechead">Citation</h2>
            <div class="abstract_text" align="left">
                If you use our work for evaluation, please cite using following bibtex entry
            </div>
            <div class="code_install">
                @misc{veeramacheneni2024fwd,
                   title={Fr\'echet Wavelet Distance: A Domain-Agnostic Metric for Image Generation}, <br>
                   author={Lokesh Veeramacheneni and Moritz Wolter and Hildegard Kuehne and Juergen Gall}, <br>
                   year={2024}, <br>
                   eprint={2312.15289}, <br>
                   archivePrefix={arXiv}, <br>
                   primaryClass={cs.CV}, <br>
                   url={https://arxiv.org/abs/2312.15289},<br>
                }
            </div>
        </div>
    </div>

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
     <!-- Bootstrap JS Bundle with Popper -->
     <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"></script>
</body>
 
</html>
